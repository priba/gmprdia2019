{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "gmprdia2019.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/priba/gmprdia2019/blob/master/gmprdia2019.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dd0__tX7I7Ji",
        "colab_type": "text"
      },
      "source": [
        "# ICDAR2019 - Graph-based Methods in Pattern Recognition & Document Image Analysis\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iCXuzl_kNMfe",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "## Change runtime of notebook to GPU\n",
        "\n",
        "\n",
        "```\n",
        "  Select Runtime -> Change Runtime type -> select runtime python 3 and hardward accelerator GPU\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wss6c9JtNP9g",
        "colab_type": "text"
      },
      "source": [
        "## Install requirements\n",
        "\n",
        "The basic libraries that will be used are:\n",
        "\n",
        "*   [Network](https://networkx.github.io/)\n",
        "*   [Pytorch](https://pytorch.org/)\n",
        "*   [DGL](https://www.dgl.ai/)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i-nm23YSArxH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip3 install networkx\n",
        "!pip3 install torch\n",
        "!pip3 install dgl-cu100"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "reFujpn4aY6W",
        "colab_type": "text"
      },
      "source": [
        "##Download Data\n",
        "\n",
        "###Letter Database\n",
        "\n",
        "Graphs that represent distorted letter drawings. They consider the 15 capital letters of the Roman alphabet that consist of straight lines only (A, E, F, H, I, K, L, M, N, T, V, W, X, Y, Z). Each node is labeled with a two-dimensional attribute giving its position relative to a reference coordinate system. Edges are unlabeled. The graph database consists of a training set, a validation set, and a test set of size 750 each. Also, three levels of distortions are provided.\n",
        "\n",
        "This dataset is part of [IAM Graph Database Repository](http://www.fki.inf.unibe.ch/databases/iam-graph-database) and it is also linked in the [IAPR TC15 resources](https://iapr-tc15.greyc.fr/links.html).\n",
        "\n",
        "It can be considered as a **TOY EXAMPLE** for graph classification.\n",
        "\n",
        "> Riesen, K. and Bunke, H.: [IAM Graph Database Repository for Graph Based Pattern Recognition and Machine Learning.](https://link.springer.com/chapter/10.1007/978-3-540-89689-0_33) In: da Vitora Lobo, N. et al. (Eds.), SSPR&SPR 2008, LNCS, vol. 5342, pp. 287-297, 2008.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tPvee9P8adH9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget https://iapr-tc15.greyc.fr/IAM/Letter.zip\n",
        "!unzip Letter.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OpPJlWzQOZ9h",
        "colab_type": "text"
      },
      "source": [
        "## Prepare data reader\n",
        "\n",
        "IAM graphs are provided as a GXL file:\n",
        "\n",
        "\n",
        "```\n",
        "<gxl>\n",
        "  <graph id=\"GRAPH_ID\" edgeids=\"false\" edgemode=\"undirected\">\n",
        "    <node id=\"_0\">\n",
        "      <attr name=\"x\">\n",
        "        <float>0.812867</float>\n",
        "      </attr>\n",
        "      <attr name=\"y\">\n",
        "        <float>0.630453</float>\n",
        "      </attr>\n",
        "    </node>\n",
        "    ...\n",
        "    <node id=\"_N\">\n",
        "      ...\n",
        "    </node>\n",
        "    <edge from=\"_0\" to=\"_1\"/>\n",
        "    ...\n",
        "    <edge from=\"_M\" to=\"_N\"/>\n",
        "  </graph>\n",
        "</gxl>\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OKTBAMj4qwO-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import xml.etree.ElementTree as ET\n",
        "import networkx as nx\n",
        "\n",
        "\n",
        "def read_letters(file):\n",
        "  \"\"\"Parse GXL file and returns a networkx graph\n",
        "  \"\"\"\n",
        "  \n",
        "  tree_gxl = ET.parse(file)\n",
        "  root_gxl = tree_gxl.getroot()\n",
        "  node_label = {}\n",
        "  node_id = []\n",
        "  \n",
        "  # Parse nodes\n",
        "  for i, node in enumerate(root_gxl.iter('node')):\n",
        "    node_id += [node.get('id')]\n",
        "    for attr in node.iter('attr'):\n",
        "      if (attr.get('name') == 'x'):\n",
        "        x = float(attr.find('float').text)\n",
        "      elif (attr.get('name') == 'y'):\n",
        "        y = float(attr.find('float').text)\n",
        "    node_label[i] = [x, y]\n",
        "\n",
        "  node_id = np.array(node_id)\n",
        "\n",
        "  # Create adjacency matrix\n",
        "  am = np.zeros((len(node_id), len(node_id)))\n",
        "  for edge in root_gxl.iter('edge'):\n",
        "    s = np.where(node_id==edge.get('from'))[0][0]\n",
        "    t = np.where(node_id==edge.get('to'))[0][0]\n",
        "\n",
        "    # Undirected Graph\n",
        "    am[s,t] = 1\n",
        "    am[t,s] = 1\n",
        "\n",
        "  # Create the networkx graph\n",
        "  G = nx.from_numpy_matrix(am)\n",
        "  nx.set_node_attributes(G, node_label, 'position')\n",
        "  \n",
        "  return G"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z9OVTKoXREfK",
        "colab_type": "text"
      },
      "source": [
        "## Load Data with NetworkX"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cLjLYEPNqUmy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "\n",
        "# Select distortion [LOW, MED, HIGH]\n",
        "distortion = 'LOW'\n",
        "\n",
        "# Select letter [A, E, F, H, I, K, L, M, N, T, V, W, X, Y, Z]\n",
        "letter = 'K'\n",
        "\n",
        "# Select id [0-149]\n",
        "id=100\n",
        "\n",
        "# Read the graph and draw it using networkx tools\n",
        "G = read_letters(os.path.join('Letter', distortion, letter+'P1_'+ str(id).zfill(4) +'.gxl'))\n",
        "nx.draw(G, pos=dict(G.nodes(data='position')))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hfHaR0QInMfd",
        "colab_type": "text"
      },
      "source": [
        "## Batch processing\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v-c6F57z7Lsk",
        "colab_type": "text"
      },
      "source": [
        "### NetworkX to DGL graph"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CSiiF2-68YKf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import dgl\n",
        "\n",
        "# Create graph object\n",
        "g = dgl.DGLGraph()\n",
        "\n",
        "# Transfer NetworkX graph with the corresponding attributes\n",
        "g.from_networkx(G, node_attrs=['position'])\n",
        "\n",
        "# Data structure\n",
        "print(g)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "te-CiqxynJq-",
        "colab_type": "text"
      },
      "source": [
        "### Define dataset\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LrImoKKY-uGI",
        "colab_type": "text"
      },
      "source": [
        "#### Dataset Division\n",
        "\n",
        "The dataset is divided by means of CXL files in *train*, *validation* and *test* with the correspondance filename and class:\n",
        "\n",
        "\n",
        "```\n",
        "<GraphCollection>\n",
        "  <fingerprints base=\"/scratch/mneuhaus/progs/letter-database/automatic/0.1\" classmodel=\"henry5\" count=\"750\">\n",
        "    <print file=\"AP1_0100.gxl\" class=\"A\"/>\n",
        "    ...\n",
        "    <print file=\"ZP1_0149.gxl\" class=\"Z\"/>\n",
        "  </fingerprints>\n",
        "</GraphCollection>\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3LHRySrwEtIG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def getFileList(file_path):\n",
        "  \"\"\"Parse CXL file and returns the corresponding file list and class\n",
        "  \"\"\"\n",
        "  \n",
        "  elements, classes = [], []\n",
        "  tree = ET.parse(file_path)\n",
        "  root = tree.getroot()\n",
        "  \n",
        "  for child in root:\n",
        "    for sec_child in child:\n",
        "      if sec_child.tag == 'print':\n",
        "        elements += [sec_child.attrib['file']]\n",
        "        classes += sec_child.attrib['class']\n",
        "        \n",
        "  return elements, classes"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MjJf_8AMm-Yv",
        "colab_type": "text"
      },
      "source": [
        "#### Define Dataset Class\n",
        "Pytorch provides an abstract class representig a dataset, ```torch.utils.data.Dataset```. We need to override two methods:\n",
        "\n",
        "*   ```__len__``` so that ```len(dataset)``` returns the size of the dataset.\n",
        "*   ```__getitem__``` to support the indexing such that ```dataset[i]``` can be used to get i-th sample\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MKj3NlYH-tKk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.utils.data as data\n",
        "\n",
        "class Letters(data.Dataset):\n",
        "  \"\"\"Letter Dataset\n",
        "  \"\"\"\n",
        "  \n",
        "  def __init__(self, root_path, file_list):\n",
        "    self.root = root_path\n",
        "    self.file_list = file_list\n",
        "    \n",
        "    # List of files and corresponding labels\n",
        "    self.graphs, self.labels = getFileList(os.path.join(self.root, self.file_list))\n",
        "    \n",
        "    # Labels to numeric value\n",
        "    self.unique_labels = np.unique(self.labels)\n",
        "    self.num_classes = len(self.unique_labels)\n",
        "    \n",
        "    self.labels = [np.where(target == self.unique_labels)[0][0] \n",
        "                   for target in self.labels]\n",
        "    \n",
        "    \n",
        "  def __getitem__(self, index):\n",
        "    # Read the graph and label\n",
        "    G = read_letters(os.path.join(self.root, self.graphs[index]))\n",
        "    target = self.labels[index]\n",
        "    \n",
        "    # Convert to DGL format\n",
        "    g = dgl.DGLGraph()\n",
        "    g.set_n_initializer(dgl.init.zero_initializer)\n",
        "    g.set_e_initializer(dgl.init.zero_initializer)\n",
        "    g.from_networkx(G, node_attrs=['position'])\n",
        "        \n",
        "    return g, target\n",
        "  \n",
        "  def label2class(self, label):\n",
        "    # Converts the numeric label to the corresponding string\n",
        "    return self.unique_labels[label]\n",
        "  \n",
        "  def __len__(self):\n",
        "    # Subset length\n",
        "    return len(self.labels)\n",
        "\n",
        "# Define the corresponding subsets for train, validation and test.\n",
        "trainset = Letters(os.path.join('Letter', distortion), 'train.cxl')\n",
        "validset = Letters(os.path.join('Letter', distortion), 'validation.cxl')\n",
        "testset = Letters(os.path.join('Letter', distortion), 'test.cxl')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8FWDCyjjPXl9",
        "colab_type": "text"
      },
      "source": [
        "### Prepare DataLoader\n",
        "\n",
        "```torch.utils.data.DataLoader``` is an iterator which provides:\n",
        "\n",
        "\n",
        "*   Data batching\n",
        "*   Shuffling the data\n",
        "*   Parallel data loading\n",
        "\n",
        "In our specific case, we need to deal with graphs of many sizes. Hence, we define a new collate function makin guse of the method ```dgl.batch```."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ea8B1D8z-TlB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "def collate(samples):\n",
        "    # The input `samples` is a list of pairs\n",
        "    #  (graph, label).\n",
        "    graphs, labels = map(list, zip(*samples))\n",
        "    batched_graph = dgl.batch(graphs)\n",
        "    return batched_graph, torch.tensor(labels)\n",
        "  \n",
        "# Define the three dataloaders. Train data will be shuffled at each epoch\n",
        "train_loader = DataLoader(trainset, batch_size=32, shuffle=True,\n",
        "                         collate_fn=collate)\n",
        "valid_loader = DataLoader(validset, batch_size=32, collate_fn=collate)\n",
        "test_loader = DataLoader(testset, batch_size=32, collate_fn=collate)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9-9eZEvJPb_r",
        "colab_type": "text"
      },
      "source": [
        "## Define Model\n",
        "\n",
        "To define a Graph Convolution, three functions have to be defined:\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "*   Message: Decide which information is sent by a node\n",
        "*   Reduce: Combine the messages and the current data\n",
        "*   NodeApply: Update the node features that are recieved from the reduce function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "02lS2sM6Pa_e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import dgl.function as fn\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# Sends a message of node feature h.\n",
        "msg = fn.copy_src(src='h', out='m')\n",
        "def message_func(edges):\n",
        "    return {'m': edges.src['h']}\n",
        "\n",
        "def reduce(nodes):\n",
        "  \"\"\"Take an average over all neighbor node features hu and use it to\n",
        "  overwrite the original node feature.\"\"\"\n",
        "  accum = torch.sum(nodes.mailbox['m'], 1)\n",
        "  return {'m': accum}\n",
        "\n",
        "class NodeApplyModule(nn.Module):\n",
        "  \"\"\"Update the node feature hv with ReLU(Whv+b).\"\"\"\n",
        "  def __init__(self, in_feats, out_feats, activation):\n",
        "    super(NodeApplyModule, self).__init__()\n",
        "    self.linear = nn.Linear(in_feats, out_feats)\n",
        "    self.activation = activation\n",
        "\n",
        "  def forward(self, node):\n",
        "    h = torch.cat([node.data['h'], node.data['m']],1)\n",
        "    h = self.linear(h)\n",
        "    h = self.activation(h)\n",
        "    return {'h' : h}  \n",
        "  \n",
        "class GCN(nn.Module):\n",
        "  \"\"\"Define a GCN layer\"\"\"\n",
        "  def __init__(self, in_feats, out_feats, activation):\n",
        "    super(GCN, self).__init__()\n",
        "    self.apply_mod = NodeApplyModule(2*in_feats, out_feats, activation)\n",
        "    \n",
        "  def forward(self, g, feature):\n",
        "    # Initialize the node features with h.\n",
        "    g.ndata['h'] = feature\n",
        "    g.update_all(msg, reduce)\n",
        "    g.apply_nodes(func=self.apply_mod)\n",
        "    return g.ndata.pop('h')\n",
        "  \n",
        "class Net(nn.Module):\n",
        "  def __init__(self, in_dim, hidden_dim, n_classes):\n",
        "    super(Net, self).__init__()\n",
        "    self.layers = nn.ModuleList([\n",
        "        GCN(in_dim, hidden_dim, F.relu),\n",
        "        GCN(hidden_dim, hidden_dim, F.relu)])\n",
        "    self.classify = nn.Linear(hidden_dim, n_classes)\n",
        "    \n",
        "  def forward(self, g):\n",
        "    # For undirected graphs, in_degree is the same as\n",
        "    # out_degree.\n",
        "    h = g.ndata['position']\n",
        "    #h = torch.cat((g.ndata['position'], g.in_degrees().view(-1, 1).float()), dim=1)\n",
        "    \n",
        "    if torch.cuda.is_available():\n",
        "      h = h.cuda() \n",
        "    for conv in self.layers:\n",
        "      h = conv(g, h)\n",
        "    g.ndata['h'] = h\n",
        "    hg = dgl.mean_nodes(g, 'h')\n",
        "    return self.classify(hg)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mXZ20gTpY3lK",
        "colab_type": "text"
      },
      "source": [
        "## New NN Modules\n",
        "\n",
        "In the last release, several Graph Convolutions are provided by default as [NN Modules](https://docs.dgl.ai/api/python/nn.pytorch.html#graphconv)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bc5FnY8gY1PJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from dgl.nn.pytorch import GraphConv\n",
        "\n",
        "class Net(nn.Module):\n",
        "  def __init__(self, in_dim, hidden_dim, n_classes):\n",
        "    super(Net, self).__init__()\n",
        "    self.layers = nn.ModuleList([\n",
        "        GraphConv(in_dim, hidden_dim, activation=F.relu),\n",
        "        GraphConv(hidden_dim, hidden_dim, activation=F.relu)])\n",
        "    self.classify = nn.Linear(hidden_dim, n_classes)\n",
        "    \n",
        "  def forward(self, g):\n",
        "    h = g.ndata['position']\n",
        "    \n",
        "    if torch.cuda.is_available():\n",
        "      h = h.cuda() \n",
        "      \n",
        "    for conv in self.layers:\n",
        "      h = conv(g, h)\n",
        "      \n",
        "    g.ndata['h'] = h\n",
        "    hg = dgl.mean_nodes(g, 'h')\n",
        "    return self.classify(hg)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8pPWJfxYUyXg",
        "colab_type": "text"
      },
      "source": [
        "## Training setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "inHmWtgwUxy-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.optim as optim\n",
        "\n",
        "model = Net(2, 256, trainset.num_classes)\n",
        "if torch.cuda.is_available():\n",
        "  model = model.cuda()\n",
        "loss_func = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
        "model.train()\n",
        "\n",
        "epoch_losses = []\n",
        "for epoch in range(80):\n",
        "  epoch_loss = 0\n",
        "  for iter, (bg, label) in enumerate(train_loader):\n",
        "    if torch.cuda.is_available():\n",
        "      label = label.cuda()\n",
        "    prediction = model(bg)\n",
        "    loss = loss_func(prediction, label)\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    epoch_loss += loss.detach().item()\n",
        "  epoch_loss /= (iter + 1)\n",
        "  print('Epoch {}, loss {:.4f}'.format(epoch, epoch_loss))\n",
        "  epoch_losses.append(epoch_loss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BkxZZXdT9Kq_",
        "colab_type": "text"
      },
      "source": [
        "## Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-peNt4q9861W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def accuracy(output, target):\n",
        "  \"\"\"Accuacy given a logit vector output and a target class\n",
        "  \"\"\"\n",
        "  _, pred = output.topk(1)\n",
        "  pred = pred.squeeze()\n",
        "  correct = pred == target\n",
        "  correct = correct.float()\n",
        "  return correct.sum() * 100.0 / correct.shape[0]\n",
        "\n",
        "\n",
        "model.eval()\n",
        "acc = 0\n",
        "with torch.no_grad():\n",
        "  for iter, (bg, label) in enumerate(test_loader):\n",
        "    if torch.cuda.is_available():\n",
        "        label = label.cuda()\n",
        "    prediction = model(bg)\n",
        "    acc += accuracy(prediction, label) * label.shape[0]\n",
        "acc = acc/len(testset)\n",
        "\n",
        "print('Test accuracy {:.4f}'.format(acc))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F-R1ZDmqkdN0",
        "colab_type": "text"
      },
      "source": [
        "## Plot results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C_Lkp4sqeg8T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from random import randrange\n",
        "import matplotlib.pyplot as plt\n",
        "for i in range(10):\n",
        "  index = randrange(len(testset))\n",
        "  g, label = testset[index]\n",
        "  pred = model(g)\n",
        "  _, pred = pred.topk(1)\n",
        "  G = g.to_networkx(node_attrs=['position'])\n",
        "  plt.figure(i)\n",
        "  position = {k: v.numpy() for k, v in dict(G.nodes(data='position')).items()}\n",
        "  nx.draw(G, pos=position, arrows=False)\n",
        "  plt.show()\n",
        "  print('Label {} {}; Prediction {} {}'.format(label, testset.label2class(label), pred.item(), testset.label2class(pred.item())))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}